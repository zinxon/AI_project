{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2018/11/keras-long-short-term-memory-lstm-model-predict-stock-prices.html\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '0700.HK'\n",
    "filename = 'daily_{}'.format(name)\n",
    "df = pd.read_csv('dataset/{}.csv'.format(filename))\n",
    "df = df.dropna()\n",
    "\n",
    "df['Date'] = pd.to_datetime(df.Date,format='%Y-%m-%d').sort_values(ascending=True)\n",
    "date = df['Date']\n",
    "# date = df['Date'].map(datetime.datetime.toordinal)\n",
    "\n",
    "valid_set_size_percentage = 10 \n",
    "test_set_size_percentage = 10 \n",
    "\n",
    "df = df.iloc[:, 4:5].values\n",
    "\n",
    "# date = np.array(date)\n",
    "# (-1,1) unknown row, 1 column\n",
    "date = date.values\n",
    "date = date.reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2471"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "df_scaled = sc.fit_transform(df)\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2018-07-18T00:00:00.000000000']\n",
      " ['2018-07-19T00:00:00.000000000']\n",
      " ['2018-07-20T00:00:00.000000000']\n",
      " ['2018-07-23T00:00:00.000000000']\n",
      " ['2018-07-24T00:00:00.000000000']\n",
      " ['2018-07-25T00:00:00.000000000']\n",
      " ['2018-07-26T00:00:00.000000000']\n",
      " ['2018-07-27T00:00:00.000000000']\n",
      " ['2018-07-30T00:00:00.000000000']\n",
      " ['2018-07-31T00:00:00.000000000']\n",
      " ['2018-08-01T00:00:00.000000000']\n",
      " ['2018-08-02T00:00:00.000000000']\n",
      " ['2018-08-03T00:00:00.000000000']\n",
      " ['2018-08-06T00:00:00.000000000']\n",
      " ['2018-08-07T00:00:00.000000000']\n",
      " ['2018-08-08T00:00:00.000000000']\n",
      " ['2018-08-09T00:00:00.000000000']\n",
      " ['2018-08-10T00:00:00.000000000']\n",
      " ['2018-08-13T00:00:00.000000000']\n",
      " ['2018-08-14T00:00:00.000000000']\n",
      " ['2018-08-15T00:00:00.000000000']\n",
      " ['2018-08-16T00:00:00.000000000']\n",
      " ['2018-08-17T00:00:00.000000000']\n",
      " ['2018-08-20T00:00:00.000000000']\n",
      " ['2018-08-21T00:00:00.000000000']\n",
      " ['2018-08-22T00:00:00.000000000']\n",
      " ['2018-08-23T00:00:00.000000000']\n",
      " ['2018-08-24T00:00:00.000000000']\n",
      " ['2018-08-27T00:00:00.000000000']\n",
      " ['2018-08-28T00:00:00.000000000']\n",
      " ['2018-08-29T00:00:00.000000000']\n",
      " ['2018-08-30T00:00:00.000000000']\n",
      " ['2018-08-31T00:00:00.000000000']\n",
      " ['2018-09-03T00:00:00.000000000']\n",
      " ['2018-09-04T00:00:00.000000000']\n",
      " ['2018-09-05T00:00:00.000000000']\n",
      " ['2018-09-06T00:00:00.000000000']\n",
      " ['2018-09-07T00:00:00.000000000']\n",
      " ['2018-09-10T00:00:00.000000000']\n",
      " ['2018-09-11T00:00:00.000000000']\n",
      " ['2018-09-12T00:00:00.000000000']\n",
      " ['2018-09-13T00:00:00.000000000']\n",
      " ['2018-09-14T00:00:00.000000000']\n",
      " ['2018-09-17T00:00:00.000000000']\n",
      " ['2018-09-18T00:00:00.000000000']\n",
      " ['2018-09-19T00:00:00.000000000']\n",
      " ['2018-09-20T00:00:00.000000000']\n",
      " ['2018-09-21T00:00:00.000000000']\n",
      " ['2018-09-24T00:00:00.000000000']\n",
      " ['2018-09-26T00:00:00.000000000']\n",
      " ['2018-09-27T00:00:00.000000000']\n",
      " ['2018-09-28T00:00:00.000000000']\n",
      " ['2018-10-02T00:00:00.000000000']\n",
      " ['2018-10-03T00:00:00.000000000']\n",
      " ['2018-10-04T00:00:00.000000000']\n",
      " ['2018-10-05T00:00:00.000000000']\n",
      " ['2018-10-08T00:00:00.000000000']\n",
      " ['2018-10-09T00:00:00.000000000']\n",
      " ['2018-10-10T00:00:00.000000000']\n",
      " ['2018-10-11T00:00:00.000000000']\n",
      " ['2018-10-12T00:00:00.000000000']\n",
      " ['2018-10-15T00:00:00.000000000']\n",
      " ['2018-10-16T00:00:00.000000000']\n",
      " ['2018-10-18T00:00:00.000000000']\n",
      " ['2018-10-19T00:00:00.000000000']\n",
      " ['2018-10-22T00:00:00.000000000']\n",
      " ['2018-10-23T00:00:00.000000000']\n",
      " ['2018-10-24T00:00:00.000000000']\n",
      " ['2018-10-25T00:00:00.000000000']\n",
      " ['2018-10-26T00:00:00.000000000']\n",
      " ['2018-10-29T00:00:00.000000000']\n",
      " ['2018-10-30T00:00:00.000000000']\n",
      " ['2018-10-31T00:00:00.000000000']\n",
      " ['2018-11-01T00:00:00.000000000']\n",
      " ['2018-11-02T00:00:00.000000000']\n",
      " ['2018-11-05T00:00:00.000000000']\n",
      " ['2018-11-06T00:00:00.000000000']\n",
      " ['2018-11-07T00:00:00.000000000']\n",
      " ['2018-11-08T00:00:00.000000000']\n",
      " ['2018-11-09T00:00:00.000000000']\n",
      " ['2018-11-12T00:00:00.000000000']\n",
      " ['2018-11-13T00:00:00.000000000']\n",
      " ['2018-11-14T00:00:00.000000000']\n",
      " ['2018-11-15T00:00:00.000000000']\n",
      " ['2018-11-16T00:00:00.000000000']\n",
      " ['2018-11-19T00:00:00.000000000']\n",
      " ['2018-11-20T00:00:00.000000000']\n",
      " ['2018-11-21T00:00:00.000000000']\n",
      " ['2018-11-22T00:00:00.000000000']\n",
      " ['2018-11-23T00:00:00.000000000']\n",
      " ['2018-11-26T00:00:00.000000000']\n",
      " ['2018-11-27T00:00:00.000000000']\n",
      " ['2018-11-28T00:00:00.000000000']\n",
      " ['2018-11-29T00:00:00.000000000']\n",
      " ['2018-11-30T00:00:00.000000000']\n",
      " ['2018-12-03T00:00:00.000000000']\n",
      " ['2018-12-04T00:00:00.000000000']\n",
      " ['2018-12-05T00:00:00.000000000']\n",
      " ['2018-12-06T00:00:00.000000000']\n",
      " ['2018-12-07T00:00:00.000000000']\n",
      " ['2018-12-10T00:00:00.000000000']\n",
      " ['2018-12-11T00:00:00.000000000']\n",
      " ['2018-12-12T00:00:00.000000000']\n",
      " ['2018-12-13T00:00:00.000000000']\n",
      " ['2018-12-14T00:00:00.000000000']\n",
      " ['2018-12-17T00:00:00.000000000']\n",
      " ['2018-12-18T00:00:00.000000000']\n",
      " ['2018-12-19T00:00:00.000000000']\n",
      " ['2018-12-20T00:00:00.000000000']\n",
      " ['2018-12-21T00:00:00.000000000']\n",
      " ['2018-12-24T00:00:00.000000000']\n",
      " ['2018-12-27T00:00:00.000000000']\n",
      " ['2018-12-28T00:00:00.000000000']\n",
      " ['2018-12-31T00:00:00.000000000']\n",
      " ['2019-01-02T00:00:00.000000000']\n",
      " ['2019-01-03T00:00:00.000000000']\n",
      " ['2019-01-04T00:00:00.000000000']\n",
      " ['2019-01-07T00:00:00.000000000']\n",
      " ['2019-01-08T00:00:00.000000000']\n",
      " ['2019-01-09T00:00:00.000000000']\n",
      " ['2019-01-10T00:00:00.000000000']\n",
      " ['2019-01-11T00:00:00.000000000']\n",
      " ['2019-01-14T00:00:00.000000000']\n",
      " ['2019-01-15T00:00:00.000000000']\n",
      " ['2019-01-16T00:00:00.000000000']\n",
      " ['2019-01-17T00:00:00.000000000']\n",
      " ['2019-01-18T00:00:00.000000000']\n",
      " ['2019-01-21T00:00:00.000000000']\n",
      " ['2019-01-22T00:00:00.000000000']\n",
      " ['2019-01-23T00:00:00.000000000']\n",
      " ['2019-01-24T00:00:00.000000000']\n",
      " ['2019-01-25T00:00:00.000000000']\n",
      " ['2019-01-28T00:00:00.000000000']\n",
      " ['2019-01-29T00:00:00.000000000']\n",
      " ['2019-01-30T00:00:00.000000000']\n",
      " ['2019-01-31T00:00:00.000000000']\n",
      " ['2019-02-01T00:00:00.000000000']\n",
      " ['2019-02-04T00:00:00.000000000']\n",
      " ['2019-02-08T00:00:00.000000000']\n",
      " ['2019-02-11T00:00:00.000000000']\n",
      " ['2019-02-12T00:00:00.000000000']\n",
      " ['2019-02-13T00:00:00.000000000']\n",
      " ['2019-02-14T00:00:00.000000000']\n",
      " ['2019-02-15T00:00:00.000000000']\n",
      " ['2019-02-18T00:00:00.000000000']\n",
      " ['2019-02-19T00:00:00.000000000']\n",
      " ['2019-02-20T00:00:00.000000000']\n",
      " ['2019-02-21T00:00:00.000000000']\n",
      " ['2019-02-22T00:00:00.000000000']\n",
      " ['2019-02-25T00:00:00.000000000']\n",
      " ['2019-02-26T00:00:00.000000000']\n",
      " ['2019-02-27T00:00:00.000000000']\n",
      " ['2019-02-28T00:00:00.000000000']\n",
      " ['2019-03-01T00:00:00.000000000']\n",
      " ['2019-03-04T00:00:00.000000000']\n",
      " ['2019-03-05T00:00:00.000000000']\n",
      " ['2019-03-06T00:00:00.000000000']\n",
      " ['2019-03-07T00:00:00.000000000']\n",
      " ['2019-03-08T00:00:00.000000000']\n",
      " ['2019-03-11T00:00:00.000000000']\n",
      " ['2019-03-12T00:00:00.000000000']\n",
      " ['2019-03-13T00:00:00.000000000']\n",
      " ['2019-03-14T00:00:00.000000000']\n",
      " ['2019-03-15T00:00:00.000000000']\n",
      " ['2019-03-18T00:00:00.000000000']\n",
      " ['2019-03-19T00:00:00.000000000']\n",
      " ['2019-03-20T00:00:00.000000000']\n",
      " ['2019-03-21T00:00:00.000000000']\n",
      " ['2019-03-22T00:00:00.000000000']\n",
      " ['2019-03-25T00:00:00.000000000']\n",
      " ['2019-03-26T00:00:00.000000000']\n",
      " ['2019-03-27T00:00:00.000000000']\n",
      " ['2019-03-28T00:00:00.000000000']\n",
      " ['2019-03-29T00:00:00.000000000']\n",
      " ['2019-04-01T00:00:00.000000000']\n",
      " ['2019-04-02T00:00:00.000000000']\n",
      " ['2019-04-03T00:00:00.000000000']\n",
      " ['2019-04-04T00:00:00.000000000']\n",
      " ['2019-04-08T00:00:00.000000000']\n",
      " ['2019-04-09T00:00:00.000000000']\n",
      " ['2019-04-10T00:00:00.000000000']\n",
      " ['2019-04-11T00:00:00.000000000']\n",
      " ['2019-04-12T00:00:00.000000000']\n",
      " ['2019-04-15T00:00:00.000000000']\n",
      " ['2019-04-16T00:00:00.000000000']\n",
      " ['2019-04-17T00:00:00.000000000']\n",
      " ['2019-04-18T00:00:00.000000000']]\n",
      "(1977, 1)\n"
     ]
    }
   ],
   "source": [
    "valid_set_size = int(np.round(valid_set_size_percentage/100*len(df)));  \n",
    "test_set_size = int(np.round(test_set_size_percentage/100*len(df)));\n",
    "train_set_size = len(df) - (valid_set_size + test_set_size);\n",
    "  \n",
    "training_set_scaled = df_scaled[:train_set_size]\n",
    "valid_set_scaled = df_scaled[train_set_size:train_set_size+valid_set_size]\n",
    "test_set_scaled = df_scaled[train_set_size+valid_set_size:]\n",
    "\n",
    "real_stock_price = df[train_set_size+valid_set_size:]\n",
    "real_stock_price = real_stock_price[60:]\n",
    "\n",
    "date_predict = date[train_set_size+valid_set_size+60:]\n",
    "print(date_predict)\n",
    "\n",
    "print(training_set_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1917, 60, 1) (187, 60, 1) (187, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# LSTMs expect our data to be in a specific format, \n",
    "# usually a 3D array. We start by creating data in 60 timesteps \n",
    "# and converting it into an array using NumPy.\n",
    "# Next, we convert the data into a 3D dimension array with X_train samples, \n",
    "# 60 timestamps, and one feature at each step.\n",
    "    \n",
    "for i in range(60, len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "    \n",
    "for i in range(60, len(valid_set_scaled)):\n",
    "    X_valid.append(valid_set_scaled[i-60:i, 0])\n",
    "    y_valid.append(valid_set_scaled[i, 0])\n",
    "    \n",
    "for i in range(60, len(test_set_scaled)):\n",
    "    X_test.append(test_set_scaled[i-60:i, 0])\n",
    "    y_test.append(test_set_scaled[i, 0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_valid, y_valid = np.array(X_valid), np.array(y_valid)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_valid = np.reshape(X_valid, (X_valid.shape[0], X_valid.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "print(X_train.shape,X_valid.shape,X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'trained_model/model/0700.HK_model_2019-04-22 11/41/42.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1887e8525e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfinishTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trained_model/model/0700.HK_model_2019-04-22 11/41/42.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'trained_model/model/0700.HK_model_2019-04-22 11/41/42.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "finishTime = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) \n",
    "\n",
    "regressor = load_model('trained_model/model/0700.HK_model_2019-04-22  11/41/42.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
    "print(predicted_stock_price.shape)\n",
    "print(real_stock_price.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18,9))\n",
    "plt.plot(date_predict,real_stock_price, color = 'black', label = '{} Stock Price'.format(name))\n",
    "plt.plot(date_predict,predicted_stock_price, color = 'green', label = 'Predicted {} Stock Price'.format(name))\n",
    "plt.title('{} Stock Price Prediction'.format(name))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('{} Stock Price'.format(name))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finishTime = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save('trained_model/model/{}_model_{}.h5'.format(name,finishTime))  # creates a HDF5 file 'my_model.h5'\n",
    "# 將參數儲存至 HDF5 檔案（不含模型）\n",
    "regressor.save_weights('trained_model/model_weight/{}_model_weights_{}.h5'.format(name,finishTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('img/{}_{}.png'.format(name,finishTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to Plotly's Figure object..\n",
    "# plotly_fig = tls.mpl_to_plotly(fig)\n",
    "plotly_fig = py.plot_mpl(fig, filename=\"my first plotly plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
